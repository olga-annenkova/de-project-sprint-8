{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efd9941",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import from_json, to_json, col, lit, struct, unix_timestamp, current_timestamp\n",
    "from pyspark.sql.types import StructType, StructField, StringType, LongType\n",
    "\n",
    "# Шаг 6 и 7 — Отправить результат в Postgres и Kafka в функции foreachBatch\n",
    "\n",
    "def foreach_batch_function(df, epoch_id):\n",
    "    \n",
    "    df.persist() # Персистентность датафрейма (шаг 8) - потом освободим память\n",
    "    \n",
    "    df_with_feedback = df.withColumn(\"feedback\", lit(None).cast(StringType())) # записываем df в PostgreSQL с полем feedback (пустое значение)\n",
    "    \n",
    "    df_with_feedback.write \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\", \"jdbc:postgresql://localhost:5432/de\") \\\n",
    "        .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "        .option(\"dbtable\", \"subscribers_feedback\") \\\n",
    "        .option(\"user\", \"student\") \\\n",
    "        .option(\"password\", \"de-student\") \\\n",
    "        .mode(\"append\") \\\n",
    "        .save()\n",
    "    \n",
    "    # создаём df для отправки в Kafka (без поля feedback)\n",
    "    \n",
    "    kafka_df = df.select(\n",
    "        \"restaurant_id\", \"adv_campaign_id\", \"adv_campaign_content\",\n",
    "        \"adv_campaign_owner\", \"adv_campaign_owner_contact\",\n",
    "        \"adv_campaign_datetime_start\", \"adv_campaign_datetime_end\",\n",
    "        \"datetime_created\", \"client_id\", \"trigger_datetime_created\"\n",
    "    )\n",
    "    \n",
    "    # json для отправки в Kafka\n",
    "    kafka_output_df = kafka_df.select(\n",
    "        to_json(struct(\"*\")).alias(\"value\")\n",
    "    )\n",
    "    \n",
    "    # отправляем сообщения в результирующий топик Kafka\n",
    "    kafka_output_df.write \\\n",
    "        .format(\"kafka\") \\\n",
    "        .option(\"kafka.bootstrap.servers\", \"rc1b-2erh7b35n4j4v869.mdb.yandexcloud.net:9091\") \\\n",
    "        .option(\"kafka.security.protocol\", \"SASL_SSL\") \\\n",
    "        .option(\"kafka.sasl.jaas.config\", 'org.apache.kafka.common.security.scram.ScramLoginModule required username=\"login\" password=\"password\";') \\\n",
    "        .option(\"kafka.sasl.mechanism\", \"SCRAM-SHA-512\") \\\n",
    "        .option(\"topic\", \"your_username_out\") \\\n",
    "        .save()\n",
    "    \n",
    "    df.unpersist() # очищаем память от df\n",
    "\n",
    "# необходимые библиотеки для интеграции Spark с Kafka и PostgreSQL\n",
    "spark_jars_packages = \",\".join([\n",
    "    \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0\",\n",
    "    \"org.postgresql:postgresql:42.4.0\",\n",
    "])\n",
    "\n",
    "# создаём spark сессию\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"RestaurantSubscribeStreamingService\") \\\n",
    "    .config(\"spark.sql.session.timeZone\", \"UTC\") \\\n",
    "    .config(\"spark.jars.packages\", spark_jars_packages) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# схема входного сообщения\n",
    "incomming_message_schema = StructType([\n",
    "    StructField(\"restaurant_id\", StringType(), True),\n",
    "    StructField(\"adv_campaign_id\", StringType(), True),\n",
    "    StructField(\"adv_campaign_content\", StringType(), True),\n",
    "    StructField(\"adv_campaign_owner\", StringType(), True),\n",
    "    StructField(\"adv_campaign_owner_contact\", StringType(), True),\n",
    "    StructField(\"adv_campaign_datetime_start\", LongType(), True),\n",
    "    StructField(\"adv_campaign_datetime_end\", LongType(), True),\n",
    "    StructField(\"datetime_created\", LongType(), True)\n",
    "])\n",
    "\n",
    "\n",
    "# Шаг — Прочитать данные об акциях из Kafka \n",
    "\n",
    "restaurant_read_stream_df = spark.readStream \\\n",
    "    .format('kafka') \\\n",
    "    .option('kafka.bootstrap.servers', 'rc1b-2erh7b35n4j4v869.mdb.yandexcloud.net:9091') \\\n",
    "    .option('kafka.security.protocol', 'SASL_SSL') \\\n",
    "    .option('kafka.sasl.jaas.config', 'org.apache.kafka.common.security.scram.ScramLoginModule required username=\"login\" password=\"password\";') \\\n",
    "    .option('kafka.sasl.mechanism', 'SCRAM-SHA-512') \\\n",
    "    .option('subscribe', 'olaann') \\\n",
    "    .load()\n",
    "\n",
    "# определяем текущее время в UTC в секундах\n",
    "current_timestamp_utc = int(round(unix_timestamp(current_timestamp())))\n",
    "\n",
    "# Шаг — Преобразование JSON в DataFrame и фильтрация сообщений по времени действия акции\n",
    "\n",
    "json_df = restaurant_read_stream_df \\\n",
    "    .select(from_json(col(\"value\").cast(\"string\"), incomming_message_schema).alias(\"data\")) \\\n",
    "    .select(\"data.*\")\n",
    "\n",
    "filtered_read_stream_df = json_df.filter(\n",
    "    (col(\"adv_campaign_datetime_start\") <= current_timestamp_utc) & \n",
    "    (col(\"adv_campaign_datetime_end\") >= current_timestamp_utc)\n",
    ")\n",
    "\n",
    "# Шаг — Прочитать данные о подписчиках из Postgres\n",
    "\n",
    "subscribers_restaurant_df = spark.read \\\n",
    "    .format('jdbc') \\\n",
    "    .option('url', 'jdbc:postgresql://localhost:5432/de') \\\n",
    "    .option('driver', 'org.postgresql.Driver') \\\n",
    "    .option('dbtable', 'subscribers_restaurants') \\\n",
    "    .option('user', 'student') \\\n",
    "    .option('password', 'de-student') \\\n",
    "    .load()\n",
    "\n",
    "# Шаг — Джойнить данные из Kafka и Postgres по restaurant_id, добавлять столбец времени создания триггера\n",
    "\n",
    "result_df = filtered_read_stream_df \\\n",
    "    .join(subscribers_restaurant_df, \"restaurant_id\") \\\n",
    "    .withColumn(\"trigger_datetime_created\", lit(current_timestamp_utc))\n",
    "\n",
    "# запускаем стриминг\n",
    "query = result_df.writeStream \\\n",
    "    .foreachBatch(foreach_batch_function) \\\n",
    "    .outputMode(\"update\") \\\n",
    "    .start()\n",
    "\n",
    "query.awaitTermination()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce164519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отправка тестового сообщения\n",
    "echo 'key:{\"restaurant_id\": \"123e4567-e89b-12d3-a456-426614174000\",\"adv_campaign_id\": \"123e4567-e89b-12d3-a456-426614174003\",\"adv_campaign_content\": \"first campaign\",\"adv_campaign_owner\": \"Ivanov Ivan Ivanovich\",\"adv_campaign_owner_contact\": \"iiivanov@restaurant.ru\",\"adv_campaign_datetime_start\": 1659203516,\"adv_campaign_datetime_end\": 2659207116,\"datetime_created\": 1659131516}' | \\\n",
    "kafkacat -b rc1b-2erh7b35n4j4v869.mdb.yandexcloud.net:9091 \\\n",
    "-X security.protocol=SASL_SSL \\\n",
    "-X sasl.mechanisms=SCRAM-SHA-512 \\\n",
    "-X sasl.username=\"student\" \\\n",
    "-X sasl.password=\"de-student\" \\\n",
    "-X ssl.ca.location=\"/ssh_private_key.pem\" \\\n",
    "-t your_username_in \\\n",
    "-K: \\\n",
    "-P"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
